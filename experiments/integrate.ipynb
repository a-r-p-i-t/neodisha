{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-Plszk2cEXX"
      },
      "outputs": [],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "eSYD0PvBcWSA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chl-10GFcfmR",
        "outputId": "f1430055-c5bb-422b-c340-4071f7764839"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolov5_model(weights_path):\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OBA-CLoacoKv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes(label_file,image_path, results):\n",
        "    image = cv2.imread(\"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\")\n",
        "    boxes = results.xyxy[0].detach().cpu().numpy()\n",
        "\n",
        "    with open(label_file, 'w') as f:\n",
        "      for i,box in enumerate(boxes):\n",
        "        print(i)\n",
        "        im=image.copy()\n",
        "        x1, y1, x2, y2 = box[:4].astype(int)\n",
        "        coord=(x1,y1,x2,y2)\n",
        "        im=im[y1:y2,x1:x2]\n",
        "        os.chdir(image_path)\n",
        "        cv2.imwrite(f\"img{i}.jpg\",im)\n",
        "        os.chdir(\"/content/drive\")\n",
        "        print(coord)\n",
        "        label = f\"{results.names[int(box[5])]}\"\n",
        "        f.write(f\"{x1} {y1} {x2} {y2}\\n\")"
      ],
      "metadata": {
        "id": "B8lDIukAcr1r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model=YOLO(model=model_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "6g5eNt3XcxPv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_roi(image_path,coord_list):\n",
        "    image=cv2.imread(image_path)\n",
        "    im=image.copy()\n",
        "\n",
        "    x1, y1, x2, y2 = coord_list\n",
        "    roi = im[y1:y2, x1:x2]\n",
        "    # roi = image[y2:y1, x1:x2]\n",
        "    return roi"
      ],
      "metadata": {
        "id": "3p_yte1OdBnt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(roi,model):\n",
        "\n",
        "    img_dir=\"/content/drive/MyDrive/data/images/\"\n",
        "    img_list = os.listdir(img_dir)\n",
        "    img_list.sort()\n",
        "    image_path=img_dir + img_list[0]\n",
        "    print(image_path)\n",
        "    print(img_list[0])\n",
        "\n",
        "    results=model.predict(source=roi,conf=0.5,save=False,show_labels=False)\n",
        "    contours=[]\n",
        "    # boxes=result.boxes\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "    i = 0\n",
        "    label_string_list =[]\n",
        "    num_objects=0\n",
        "    num_emptys=0\n",
        "    while i < len(boxes.xyxy.tolist()):\n",
        "\n",
        "      bbox = boxes.xyxy.tolist()[i]\n",
        "      class_id = int(boxes.cls.tolist()[i])\n",
        "      if class_id==0:\n",
        "        num_objects +=1\n",
        "      else:\n",
        "        num_emptys +=1\n",
        "      i+=1\n",
        "    return num_objects,num_emptys\n",
        "    print(\"Objects:\",num_objects)\n",
        "    print(\"emptys:\",num_emptys)"
      ],
      "metadata": {
        "id": "l8feetzydEcu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = \"/content/drive/MyDrive/phase_2.pt\"\n",
        "image=cv2.imread(\"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\")\n",
        "model = load_yolov5_model(weights_path)\n",
        "results=model(image)\n",
        "image_path=\"/content/drive/MyDrive/data\"\n",
        "label_file=\"/content/drive/MyDrive/data/output\"\n",
        "draw_bounding_boxes(label_file,image_path, results)\n",
        "model_path=\"/content/drive/MyDrive/best_detect.pt\"\n",
        "model=load_model(model_path)\n",
        "results_dict={}\n",
        "# output_path=\"/content/drive/MyDrive/data/output\"\n",
        "output_path=label_file\n",
        "bounding_box_list=[]\n",
        "with open(output_path, 'r') as f:\n",
        "   for line in f:\n",
        "    bounding_box = [int(coord) for coord in line.strip().split()]\n",
        "    bounding_box_list.append(bounding_box)\n",
        "destination_path = \"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\"\n",
        "results_dict[\"image_name\"] = destination_path.split(\"/\")[-1]\n",
        "results_dict[\"coordinates\"]=bounding_box_list\n",
        "counts_list=[]\n",
        "\n",
        "\n",
        "for i in range(len(bounding_box_list)):\n",
        "  roi = extract_roi(destination_path,bounding_box_list[i])\n",
        "  num_objs,num_empts=extract_labels(roi,model)\n",
        "  counts_list.append([num_objs,num_empts])\n",
        "results_dict[\"count\"] = counts_list\n",
        "print(results_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srV8qLR1dMri",
        "outputId": "092607ad-d00e-4bd3-dbe0-54a168e9b815"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2023-7-25 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20856975 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(2859, 334, 4396, 1304)\n",
            "1\n",
            "(782, 1769, 1607, 2196)\n",
            "2\n",
            "(2875, 1448, 4471, 2443)\n",
            "3\n",
            "(2881, 2654, 4582, 3456)\n",
            "4\n",
            "(694, 2623, 1553, 3123)\n",
            "5\n",
            "(791, 705, 1634, 1487)\n",
            "6\n",
            "(1651, 1731, 2786, 2234)\n",
            "7\n",
            "(1, 2382, 613, 3039)\n",
            "8\n",
            "(1600, 2673, 2798, 3332)\n",
            "9\n",
            "(3, 1650, 718, 2250)\n",
            "10\n",
            "(70, 860, 771, 1534)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0: 416x640 4 objects, 149.8ms\n",
            "Speed: 4.6ms preprocess, 149.8ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "0: 352x640 3 objects, 65.9ms\n",
            "Speed: 2.9ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 416x640 3 objects, 13.4ms\n",
            "Speed: 5.3ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 320x640 3 objects, 58.9ms\n",
            "Speed: 4.5ms preprocess, 58.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 3 objects, 63.4ms\n",
            "Speed: 3.3ms preprocess, 63.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 608x640 5 objects, 61.1ms\n",
            "Speed: 3.8ms preprocess, 61.1ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 288x640 3 objects, 63.4ms\n",
            "Speed: 2.5ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 640x608 6 objects, 59.6ms\n",
            "Speed: 6.1ms preprocess, 59.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 352x640 3 objects, 11.2ms\n",
            "Speed: 4.3ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 544x640 10 objects, 60.7ms\n",
            "Speed: 4.7ms preprocess, 60.7ms inference, 2.4ms postprocess per image at shape (1, 3, 544, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 640x640 14 objects, 16.7ms\n",
            "Speed: 5.3ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n",
            "{'image_name': 'Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg', 'coordinates': [[2859, 334, 4396, 1304], [782, 1769, 1607, 2196], [2875, 1448, 4471, 2443], [2881, 2654, 4582, 3456], [694, 2623, 1553, 3123], [791, 705, 1634, 1487], [1651, 1731, 2786, 2234], [1, 2382, 613, 3039], [1600, 2673, 2798, 3332], [3, 1650, 718, 2250], [70, 860, 771, 1534]], 'count': [[4, 0], [3, 0], [3, 0], [3, 0], [3, 0], [5, 0], [3, 0], [6, 0], [3, 0], [10, 0], [14, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsEWod3mnpiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}