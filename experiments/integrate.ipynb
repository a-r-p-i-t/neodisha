{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-Plszk2cEXX"
      },
      "outputs": [],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "eSYD0PvBcWSA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chl-10GFcfmR",
        "outputId": "7a7f8dd9-1810-418e-c2dc-903f78755fb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolov5_model(weights_path):\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OBA-CLoacoKv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes(label_file,image_path, results):\n",
        "    image = cv2.imread(\"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\")\n",
        "    boxes = results.xyxy[0].detach().cpu().numpy()\n",
        "\n",
        "    with open(label_file, 'w') as f:\n",
        "      for i,box in enumerate(boxes):\n",
        "        print(i)\n",
        "        im=image.copy()\n",
        "        x1, y1, x2, y2 = box[:4].astype(int)\n",
        "        coord=(x1,y1,x2,y2)\n",
        "        im=im[y1:y2,x1:x2]\n",
        "        # os.chdir(image_path)\n",
        "        # cv2.imwrite(f\"img{i}.jpg\",im)\n",
        "        # os.chdir(\"/content/drive\")\n",
        "        print(coord)\n",
        "        label = f\"{results.names[int(box[5])]}\"\n",
        "        f.write(f\"{x1} {y1} {x2} {y2}\\n\")"
      ],
      "metadata": {
        "id": "B8lDIukAcr1r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model=YOLO(model=model_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "6g5eNt3XcxPv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_roi(image_path,coord_list,i):\n",
        "    image=cv2.imread(image_path)\n",
        "    im=image.copy()\n",
        "\n",
        "    x1, y1, x2, y2 = coord_list\n",
        "    roi = im[y1:y2, x1:x2]\n",
        "\n",
        "    cv2.imwrite(f\"roi{i}.jpg\",roi)\n",
        "    return roi"
      ],
      "metadata": {
        "id": "3p_yte1OdBnt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(roi,model,i):\n",
        "\n",
        "    img_dir=\"/content/drive/MyDrive/data/images/\"\n",
        "    img_list = os.listdir(img_dir)\n",
        "    img_list.sort()\n",
        "    image_path=img_dir + img_list[0]\n",
        "    print(image_path)\n",
        "    print(img_list[0])\n",
        "\n",
        "    # results=model.predict(source=roi,conf=0.5,save=False,show_labels=False)\n",
        "    results=model.predict(source=f\"roi{i}.jpg\",conf=0.5,save=False,save_txt=True)\n",
        "    contours=[]\n",
        "    # boxes=result.boxes\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "    i = 0\n",
        "    label_string_list =[]\n",
        "    num_objects=0\n",
        "    num_emptys=0\n",
        "    while i < len(boxes.xyxy.tolist()):\n",
        "\n",
        "      bbox = boxes.xyxy.tolist()[i]\n",
        "      class_id = int(boxes.cls.tolist()[i])\n",
        "      if class_id==0:\n",
        "        num_objects +=1\n",
        "      else:\n",
        "        num_emptys +=1\n",
        "      i+=1\n",
        "    return num_objects,num_emptys\n",
        "    print(\"Objects:\",num_objects)\n",
        "    print(\"emptys:\",num_emptys)"
      ],
      "metadata": {
        "id": "l8feetzydEcu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = \"/content/drive/MyDrive/phase_2.pt\"\n",
        "image=cv2.imread(\"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\")\n",
        "model = load_yolov5_model(weights_path)\n",
        "results=model(image)\n",
        "image_path=\"/content/drive/MyDrive/data\"\n",
        "label_file=\"/content/drive/MyDrive/data/output\"\n",
        "draw_bounding_boxes(label_file,image_path, results)\n",
        "model_path=\"/content/drive/MyDrive/best_detect.pt\"\n",
        "model=load_model(model_path)\n",
        "results_dict={}\n",
        "output_path=label_file\n",
        "bounding_box_list=[]\n",
        "with open(output_path, 'r') as f:\n",
        "   for line in f:\n",
        "    bounding_box = [int(coord) for coord in line.strip().split()]\n",
        "    bounding_box_list.append(bounding_box)\n",
        "destination_path = \"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\"\n",
        "results_dict[\"image_name\"] = destination_path.split(\"/\")[-1]\n",
        "results_dict[\"coordinates\"]=bounding_box_list\n",
        "counts_list=[]\n",
        "\n",
        "\n",
        "for i in range(len(bounding_box_list)):\n",
        "  roi = extract_roi(destination_path,bounding_box_list[i],i)\n",
        "  num_objs,num_empts=extract_labels(roi,model,i)\n",
        "  counts_list.append([num_objs,num_empts])\n",
        "results_dict[\"count\"] = counts_list\n",
        "print(results_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srV8qLR1dMri",
        "outputId": "c20a8c2c-8298-44e9-94e2-a6aba9f108ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "WARNING ‚ö†Ô∏è 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
            "WARNING ‚ö†Ô∏è 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
            "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
            "    import torch\n",
            "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
            "    torch.save(ckpt, \"updated-model.pt\")\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188.5/188.5 kB 4.6 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 62.7/62.7 kB 168.8 MB/s eta 0:00:00\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.32 smmap-5.0.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 5.9s, installed 1 package: ['gitpython>=3.1.30']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 üöÄ 2023-7-25 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20856975 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(2859, 334, 4396, 1304)\n",
            "1\n",
            "(782, 1769, 1607, 2196)\n",
            "2\n",
            "(2875, 1448, 4471, 2443)\n",
            "3\n",
            "(2881, 2654, 4582, 3456)\n",
            "4\n",
            "(694, 2623, 1553, 3123)\n",
            "5\n",
            "(791, 705, 1634, 1487)\n",
            "6\n",
            "(1651, 1731, 2786, 2234)\n",
            "7\n",
            "(1, 2382, 613, 3039)\n",
            "8\n",
            "(1600, 2673, 2798, 3332)\n",
            "9\n",
            "(3, 1650, 718, 2250)\n",
            "10\n",
            "(70, 860, 771, 1534)\n",
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi0.jpg: 416x640 4 objects, 114.8ms\n",
            "Speed: 3.5ms preprocess, 114.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "1 label saved to runs/detect/predict/labels\n",
            "\n",
            "image 1/1 /content/roi1.jpg: 352x640 3 objects, 71.2ms\n",
            "Speed: 1.9ms preprocess, 71.2ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "2 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi2.jpg: 416x640 3 objects, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "3 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi3.jpg: 320x640 3 objects, 83.8ms\n",
            "Speed: 2.1ms preprocess, 83.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "4 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi4.jpg: 384x640 3 objects, 63.8ms\n",
            "Speed: 1.9ms preprocess, 63.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "5 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi5.jpg: 608x640 5 objects, 70.4ms\n",
            "Speed: 3.0ms preprocess, 70.4ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "6 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi6.jpg: 288x640 3 objects, 67.6ms\n",
            "Speed: 2.1ms preprocess, 67.6ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "7 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi7.jpg: 640x608 6 objects, 63.3ms\n",
            "Speed: 2.6ms preprocess, 63.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "8 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi8.jpg: 352x640 3 objects, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "9 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi9.jpg: 544x640 10 objects, 72.7ms\n",
            "Speed: 2.6ms preprocess, 72.7ms inference, 1.8ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "10 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi10.jpg: 640x640 14 objects, 17.0ms\n",
            "Speed: 2.7ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "11 labels saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.jpg\n",
            "images0.jpg\n",
            "{'image_name': 'Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg', 'coordinates': [[2859, 334, 4396, 1304], [782, 1769, 1607, 2196], [2875, 1448, 4471, 2443], [2881, 2654, 4582, 3456], [694, 2623, 1553, 3123], [791, 705, 1634, 1487], [1651, 1731, 2786, 2234], [1, 2382, 613, 3039], [1600, 2673, 2798, 3332], [3, 1650, 718, 2250], [70, 860, 771, 1534]], 'count': [[4, 0], [3, 0], [3, 0], [3, 0], [3, 0], [5, 0], [3, 0], [6, 0], [3, 0], [10, 0], [14, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsEWod3mnpiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}