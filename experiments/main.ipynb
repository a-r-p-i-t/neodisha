{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "x47KoPvXa6zh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "# from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "from mobile_sam import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAV0U95tcwfG",
        "outputId": "cea15826-09cc-4c59-869e-f3b31bc064f9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sam_checkpoint = \"/content/drive/MyDrive/sam_vit_h_4b8939.pth\"\n",
        "sam_checkpoint = \"/content/drive/MyDrive/mobile_sam.pt\"\n",
        "# model_type = \"vit_h\"\n",
        "model_type = \"vit_t\"\n",
        "device=\"cuda\"\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "W_JIlOm1a_oe"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)"
      ],
      "metadata": {
        "id": "xDdHBNSpbDjJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)"
      ],
      "metadata": {
        "id": "cjhA8j0rbN8q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
      ],
      "metadata": {
        "id": "dWuRZR1fbRuD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_points(contour_points, image_width, image_height):\n",
        "    # Normalize the points\n",
        "    normalized_points = contour_points.astype(float) / np.array([image_width, image_height])\n",
        "    return normalized_points"
      ],
      "metadata": {
        "id": "J3m5098-bVFr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_contour_to_yolov8(contour_points, class_index):\n",
        "    # Flatten the contour points to a 1D array\n",
        "    flattened_points = contour_points.reshape(-1, 2)\n",
        "\n",
        "    # Create YOLOv8 label string\n",
        "    label_string = f\"{class_index}\"\n",
        "    for point in flattened_points:\n",
        "        label_string += f\" {point[0]} {point[1]}\"\n",
        "    return label_string"
      ],
      "metadata": {
        "id": "dtmDHzqdbXoB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image_from_drive(url, destination):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(destination, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(\"Image downloaded successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "avllqSrWbaTM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://drive.google.com/uc?id=1RjaSIfNz11fcRvWgL1ER4ZWttxIZ8zzY\"\n",
        "destination_path = \"/content/drive/MyDrive/data/images/images.jpg\""
      ],
      "metadata": {
        "id": "19usAjfYbdSD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_roi(image_path,coord_list):\n",
        "    image=cv2.imread(image_path)\n",
        "    print(\"Coord List:\", coord_list)\n",
        "    x1, y1, x2, y2 = coord_list\n",
        "    roi = image[y1:y2, x1:x2]\n",
        "    # roi = image[y2:y1, x1:x2]\n",
        "    return roi"
      ],
      "metadata": {
        "id": "iED5X7mEbfxO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model=YOLO(model=model_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "QUa1Sxlqbn9D"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(roi,model):\n",
        "\n",
        "    img_dir=\"/content/drive/MyDrive/data/images/\"\n",
        "    img_list = os.listdir(img_dir)\n",
        "    img_list.sort()\n",
        "    image_path=img_dir + img_list[0]\n",
        "    print(image_path)\n",
        "    print(img_list[0])\n",
        "\n",
        "    results=model.predict(source=roi,conf=0.5,save=True,show_labels=False)\n",
        "    contours=[]\n",
        "    # boxes=result.boxes\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "    i = 0\n",
        "    label_string_list =[]\n",
        "    while i < len(boxes.xyxy.tolist()):\n",
        "        bbox = boxes.xyxy.tolist()[i]\n",
        "        class_id = boxes.cls.tolist()[i]\n",
        "        # print(bbox)\n",
        "\n",
        "        # image = cv2.cvtColor(cv2.imread(roi), cv2.COLOR_BGR2RGB)\n",
        "        predictor.set_image(roi)\n",
        "        input_box = np.array(bbox)\n",
        "        masks, _, _ = predictor.predict(\n",
        "            point_coords=None,\n",
        "            point_labels=None,\n",
        "            box=input_box,\n",
        "            multimask_output=False,\n",
        "        )\n",
        "        # print(masks)\n",
        "        mask = masks[0]\n",
        "        # print(mask)\n",
        "        contour, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        contours.extend(contour)\n",
        "\n",
        "        contour_points = contours[i]\n",
        "        class_index = int(class_id)\n",
        "        image_height, image_width = roi.shape[:2]\n",
        "\n",
        "        normalized_points = normalize_points(contour_points, image_width, image_height)\n",
        "        label_string = convert_contour_to_yolov8(normalized_points, class_index)\n",
        "        label_string_list.append(label_string)\n",
        "        i += 1\n",
        "    return label_string_list\n",
        "    # output_path =image_path.split(\".\")[0] + '.txt'\n",
        "    # print(output_path)\n",
        "    # with open(output_path, 'w') as file:\n",
        "    #     for item in label_string_list:\n",
        "    #         file.write(str(item) + '\\n')\n"
      ],
      "metadata": {
        "id": "VZoCoY0LbsJg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=time.time()\n",
        "model_path=\"/content/drive/MyDrive/best_detect.pt\"\n",
        "model=load_model(model_path)\n",
        "bounding_box_list=[[1046, 298, 1152, 419],[720,217,862,320],[755,351,899,463],[689,85,832,184],[355,446,568,548],[583,403,754,492],[0,57,258,239],[545,254,715,328],[277,62,489,209],[888,184,1026,297],[15,278,290,436],[978,75,1112,165],[48,466,327,645],[920,314,1044,423],[1046,298,1152,419]]\n",
        "images_path=\"/content/VID_20220718_161715_0009.jpg\"\n",
        "download_image_from_drive(image_url, destination_path)\n",
        "for i in range(len(bounding_box_list)):\n",
        "  roi=extract_roi(destination_path,bounding_box_list[i])\n",
        "  label_string_list=extract_labels(roi,model)\n",
        "  output_path =destination_path.split(\".\")[0] + f'{i}.txt'\n",
        "  print(output_path)\n",
        "  with open(output_path, 'w') as file:\n",
        "      for item in label_string_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "  file.close()\n",
        "  with open(output_path, 'r') as file:\n",
        "      lines = file.readlines()\n",
        "      num_ones = 0\n",
        "      num_zeros = 0\n",
        "      for line in lines:\n",
        "        line_list = line.split()\n",
        "        class_label = int(line_list[0])\n",
        "        if class_label == 1:\n",
        "            num_ones += 1\n",
        "        elif class_label == 0:\n",
        "            num_zeros += 1\n",
        "      print(\"Number of emptys:\", num_ones)\n",
        "      print(\"Number of objects:\", num_zeros)\n",
        "end_time=time.time()\n",
        "print(\"Total Time :\",end_time-start_time)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZxXRdd4bw-P",
        "outputId": "8ed45a1b-85e6-42cf-88ff-a62670001932"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image downloaded successfully.\n",
            "Coord List: [1046, 298, 1152, 419]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 640x576 1 object, 17.2ms\n",
            "Speed: 2.5ms preprocess, 17.2ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 576)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n",
            "\n",
            "0: 480x640 3 objects, 22.1ms\n",
            "Speed: 2.9ms preprocess, 22.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images0.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 1\n",
            "Coord List: [720, 217, 862, 320]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 512x640 3 objects, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images1.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 3\n",
            "Coord List: [755, 351, 899, 463]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 448x640 5 objects, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images2.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 3\n",
            "Coord List: [689, 85, 832, 184]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 320x640 3 objects, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images3.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 5\n",
            "Coord List: [355, 446, 568, 548]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 352x640 3 objects, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images4.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 3\n",
            "Coord List: [583, 403, 754, 492]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 480x640 5 objects, 4 emptys, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images5.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 3\n",
            "Coord List: [0, 57, 258, 239]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 288x640 3 objects, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images6.txt\n",
            "Number of emptys: 4\n",
            "Number of objects: 5\n",
            "Coord List: [545, 254, 715, 328]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 448x640 5 objects, 7.1ms\n",
            "Speed: 2.4ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images7.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 3\n",
            "Coord List: [277, 62, 489, 209]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 544x640 10 objects, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images8.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 5\n",
            "Coord List: [888, 184, 1026, 297]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 10 emptys, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images9.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 10\n",
            "Coord List: [15, 278, 290, 436]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 448x640 9 objects, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images10.txt\n",
            "Number of emptys: 10\n",
            "Number of objects: 0\n",
            "Coord List: [978, 75, 1112, 165]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 416x640 6 emptys, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images11.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 9\n",
            "Coord List: [48, 466, 327, 645]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 576x640 3 objects, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images12.txt\n",
            "Number of emptys: 6\n",
            "Number of objects: 0\n",
            "Coord List: [920, 314, 1044, 423]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 640x576 1 object, 8.4ms\n",
            "Speed: 4.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n",
            "Results saved to \u001b[1mruns/detect/predict34\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data/images/images13.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 3\n",
            "Coord List: [1046, 298, 1152, 419]\n",
            "/content/drive/MyDrive/data/images/images.jpg\n",
            "images.jpg\n",
            "/content/drive/MyDrive/data/images/images14.txt\n",
            "Number of emptys: 0\n",
            "Number of objects: 1\n",
            "Total Time : 8.117621183395386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB6ynYDjj4Lv",
        "outputId": "fcfff2c7-9571-444b-875a-2c00eeeed148"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.139-py3-none-any.whl (605 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.9/605.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics\n",
            "Successfully installed ultralytics-8.0.139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install segment_anything"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1PeWlnIkCnb",
        "outputId": "a6a9ec2e-6b32-4ae8-dd11-ffdca1ba1e54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segment_anything\n",
            "  Downloading segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: segment_anything\n",
            "Successfully installed segment_anything-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/ChaoningZhang/MobileSAM.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ugy1Sgevif",
        "outputId": "263f7989-a935-4143-8b31-8f0bcabaa0b6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ChaoningZhang/MobileSAM.git\n",
            "  Cloning https://github.com/ChaoningZhang/MobileSAM.git to /tmp/pip-req-build-wypfj2o4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ChaoningZhang/MobileSAM.git /tmp/pip-req-build-wypfj2o4\n",
            "  Resolved https://github.com/ChaoningZhang/MobileSAM.git to commit 01ea8d0f5590082f0c1ceb0a3e2272593f20154b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mobile-sam\n",
            "  Building wheel for mobile-sam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mobile-sam: filename=mobile_sam-1.0-py3-none-any.whl size=42433 sha256=c0311e3ea7b5828ae811d2636acfb557d0051e1cde82c495e874fb5d48b73fb4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8g6c6g37/wheels/43/b1/9d/1c1b33c31d4c54f0a502f9c48b655f87213ab01e55d09cf4ef\n",
            "Successfully built mobile-sam\n",
            "Installing collected packages: mobile-sam\n",
            "Successfully installed mobile-sam-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fEuyyzkfglv",
        "outputId": "c8e9e931-28c1-4d0e-d14a-2b7d63bd8b55"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    }
  ]
}