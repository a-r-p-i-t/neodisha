{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8-Plszk2cEXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40944fd2-6932-4a0c-ed00-0db3e2637c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.142-py3-none-any.whl (607 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m608.0/608.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics\n",
            "Successfully installed ultralytics-8.0.142\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "eSYD0PvBcWSA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chl-10GFcfmR",
        "outputId": "d64a17ca-6057-4609-8e83-bbb023755d3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolov5_model(weights_path):\n",
        "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OBA-CLoacoKv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes(label_file, results):\n",
        "    image = cv2.imread(\"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\")\n",
        "    boxes = results.xyxy[0].detach().cpu().numpy()\n",
        "\n",
        "    with open(label_file, 'w') as f:\n",
        "      for i,box in enumerate(boxes):\n",
        "        im=image.copy()\n",
        "        x1, y1, x2, y2 = box[:4].astype(int)\n",
        "        coord=(x1,y1,x2,y2)\n",
        "        im=im[y1:y2,x1:x2]\n",
        "        # os.chdir(image_path)\n",
        "        # cv2.imwrite(f\"img{i}.jpg\",im)\n",
        "        # os.chdir(\"/content/drive\")\n",
        "        print(coord)\n",
        "        label = f\"{results.names[int(box[5])]}\"\n",
        "        f.write(f\"{x1} {y1} {x2} {y2}\\n\")"
      ],
      "metadata": {
        "id": "B8lDIukAcr1r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model=YOLO(model=model_path)\n",
        "    return model"
      ],
      "metadata": {
        "id": "6g5eNt3XcxPv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_roi(image_path,coord_list,i,j):\n",
        "    image=cv2.imread(image_path)\n",
        "    im=image.copy()\n",
        "\n",
        "    x1, y1, x2, y2 = coord_list\n",
        "    roi = im[y1:y2, x1:x2]\n",
        "\n",
        "    cv2.imwrite(f\"roi{j}{i}.jpg\",roi)\n",
        "    return roi"
      ],
      "metadata": {
        "id": "3p_yte1OdBnt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_labels(roi,model,i,j):\n",
        "\n",
        "\n",
        "\n",
        "    results=model.predict(source=f\"roi{j}{i}.jpg\",conf=0.9,save=True,save_txt=True,show_labels=False)\n",
        "    contours=[]\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "    i = 0\n",
        "    label_string_list =[]\n",
        "    num_objects=0\n",
        "    num_emptys=0\n",
        "    while i < len(boxes.xyxy.tolist()):\n",
        "\n",
        "      bbox = boxes.xyxy.tolist()[i]\n",
        "      class_id = int(boxes.cls.tolist()[i])\n",
        "      if class_id==0:\n",
        "        num_objects +=1\n",
        "      else:\n",
        "        num_emptys +=1\n",
        "      i+=1\n",
        "    return num_objects,num_emptys\n",
        "    print(\"Objects:\",num_objects)\n",
        "    print(\"emptys:\",num_emptys)"
      ],
      "metadata": {
        "id": "l8feetzydEcu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = \"/content/drive/MyDrive/phase_2.pt\"\n",
        "model = load_yolov5_model(weights_path)\n",
        "model_path=\"/content/drive/MyDrive/latest_detection_model.pt\"\n",
        "image_list=[\"/content/drive/MyDrive/1663135227502.62cd7c06be8154e6d5c866b4.jpg\",\"/content/drive/MyDrive/Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg\"]\n",
        "parent_list=[]\n",
        "model1=load_model(model_path)\n",
        "for j in range(len(image_list)):\n",
        "\n",
        "  image=cv2.imread(image_list[j])\n",
        "\n",
        "  results=model(image)\n",
        "  label_file=\"/content/drive/MyDrive/data/output{j}\"\n",
        "  draw_bounding_boxes(label_file, results)\n",
        "  results_dict={}\n",
        "  output_path=label_file\n",
        "  bounding_box_list=[]\n",
        "  with open(output_path, 'r') as f:\n",
        "    for line in f:\n",
        "      bounding_box = [int(coord) for coord in line.strip().split()]\n",
        "      bounding_box_list.append(bounding_box)\n",
        "  destination_path = image_list[j]\n",
        "  results_dict[\"image_name\"] = destination_path.split(\"/\")[-1]\n",
        "  results_dict[\"image_id\"] = j\n",
        "  results_dict[\"coordinates\"]=bounding_box_list\n",
        "  counts_list=[]\n",
        "\n",
        "\n",
        "  for i in range(len(bounding_box_list)):\n",
        "    roi = extract_roi(destination_path,bounding_box_list[i],i,j)\n",
        "    num_objs,num_empts=extract_labels(roi,model1,i,j)\n",
        "    counts_list.append([num_objs,num_empts])\n",
        "  results_dict[\"count\"] = counts_list\n",
        "  parent_list.append(results_dict)\n",
        "print(parent_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srV8qLR1dMri",
        "outputId": "08c85fe1-0a34-4fd2-f59b-eaa5ace0989a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 ðŸš€ 2023-7-26 Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20856975 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26, 0, 1642, 988)\n",
            "(3170, 288, 4381, 1190)\n",
            "(1704, 19, 3109, 1059)\n",
            "(1699, 1075, 3153, 2157)\n",
            "(1683, 2215, 3159, 3339)\n",
            "(3176, 1240, 4516, 2193)\n",
            "(3239, 2416, 4608, 3352)\n",
            "(3, 2332, 1517, 3396)\n",
            "(0, 2321, 1545, 3410)\n",
            "(3234, 2415, 4605, 3347)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi00.jpg: 416x640 (no detections), 36.4ms\n",
            "Speed: 12.3ms preprocess, 36.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "0 label saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi01.jpg: 480x640 20 objects, 1 empty, 29.3ms\n",
            "Speed: 4.0ms preprocess, 29.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "1 label saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi02.jpg: 480x640 15 objects, 28.3ms\n",
            "Speed: 3.7ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "2 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi03.jpg: 480x640 20 objects, 28.2ms\n",
            "Speed: 2.6ms preprocess, 28.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "3 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi04.jpg: 512x640 11 objects, 29.4ms\n",
            "Speed: 2.6ms preprocess, 29.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "4 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi05.jpg: 480x640 23 objects, 31.6ms\n",
            "Speed: 2.5ms preprocess, 31.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "5 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi06.jpg: 448x640 1 object, 28.8ms\n",
            "Speed: 2.3ms preprocess, 28.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "6 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi07.jpg: 480x640 18 objects, 31.4ms\n",
            "Speed: 2.4ms preprocess, 31.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "7 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi08.jpg: 480x640 19 objects, 28.3ms\n",
            "Speed: 2.6ms preprocess, 28.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "8 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi09.jpg: 448x640 1 object, 28.6ms\n",
            "Speed: 2.4ms preprocess, 28.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "9 labels saved to runs/detect/predict6/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2859, 334, 4396, 1304)\n",
            "(782, 1769, 1607, 2196)\n",
            "(2875, 1448, 4471, 2443)\n",
            "(2881, 2654, 4582, 3456)\n",
            "(694, 2623, 1553, 3123)\n",
            "(791, 705, 1634, 1487)\n",
            "(1651, 1731, 2786, 2234)\n",
            "(1, 2382, 613, 3039)\n",
            "(1600, 2673, 2798, 3332)\n",
            "(3, 1650, 718, 2250)\n",
            "(70, 860, 771, 1534)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/roi10.jpg: 416x640 4 objects, 28.7ms\n",
            "Speed: 2.4ms preprocess, 28.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "10 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi11.jpg: 352x640 (no detections), 26.2ms\n",
            "Speed: 1.7ms preprocess, 26.2ms inference, 0.8ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "10 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi12.jpg: 416x640 2 objects, 29.4ms\n",
            "Speed: 2.2ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "11 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi13.jpg: 320x640 3 objects, 23.3ms\n",
            "Speed: 1.9ms preprocess, 23.3ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "12 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi14.jpg: 384x640 2 objects, 26.5ms\n",
            "Speed: 2.5ms preprocess, 26.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "13 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi15.jpg: 608x640 2 objects, 37.2ms\n",
            "Speed: 2.6ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "14 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi16.jpg: 288x640 (no detections), 22.6ms\n",
            "Speed: 2.2ms preprocess, 22.6ms inference, 0.9ms postprocess per image at shape (1, 3, 288, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "14 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi17.jpg: 640x608 5 objects, 37.2ms\n",
            "Speed: 2.5ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "15 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi18.jpg: 352x640 3 objects, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "16 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi19.jpg: 544x640 3 objects, 35.8ms\n",
            "Speed: 2.3ms preprocess, 35.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "17 labels saved to runs/detect/predict6/labels\n",
            "\n",
            "image 1/1 /content/roi110.jpg: 640x640 4 objects, 38.1ms\n",
            "Speed: 2.6ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict6\u001b[0m\n",
            "18 labels saved to runs/detect/predict6/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image_name': '1663135227502.62cd7c06be8154e6d5c866b4.jpg', 'image_id': 0, 'coordinates': [[26, 0, 1642, 988], [3170, 288, 4381, 1190], [1704, 19, 3109, 1059], [1699, 1075, 3153, 2157], [1683, 2215, 3159, 3339], [3176, 1240, 4516, 2193], [3239, 2416, 4608, 3352], [3, 2332, 1517, 3396], [0, 2321, 1545, 3410], [3234, 2415, 4605, 3347]], 'count': [[0, 0], [20, 1], [15, 0], [20, 0], [11, 0], [23, 0], [1, 0], [18, 0], [19, 0], [1, 0]]}, {'image_name': 'Trends-Seawoods-NaviMumbai_train_17-09-2022_0003.jpg', 'image_id': 1, 'coordinates': [[2859, 334, 4396, 1304], [782, 1769, 1607, 2196], [2875, 1448, 4471, 2443], [2881, 2654, 4582, 3456], [694, 2623, 1553, 3123], [791, 705, 1634, 1487], [1651, 1731, 2786, 2234], [1, 2382, 613, 3039], [1600, 2673, 2798, 3332], [3, 1650, 718, 2250], [70, 860, 771, 1534]], 'count': [[4, 0], [0, 0], [2, 0], [3, 0], [2, 0], [2, 0], [0, 0], [5, 0], [3, 0], [3, 0], [4, 0]]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsEWod3mnpiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}